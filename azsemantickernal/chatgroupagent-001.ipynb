{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6811f68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.agents import ChatCompletionAgent, AgentGroupChat\n",
    "from semantic_kernel.functions import KernelFunctionFromPrompt\n",
    "from semantic_kernel.agents.strategies import (\n",
    "    KernelFunctionSelectionStrategy,\n",
    "    KernelFunctionTerminationStrategy,\n",
    ")\n",
    "from semantic_kernel.contents import ChatHistoryTruncationReducer\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "BUSINESS_ANALYST = \"BusinessAnalyst\"\n",
    "SOFTWARE_ENGINEER = \"SoftwareEngineer\"\n",
    "PRODUCT_MANAGER = \"ProductManager\"\n",
    "\n",
    "\n",
    "\n",
    "kernel = Kernel()\n",
    "\n",
    "\n",
    "\n",
    "# Create agents for different roles\n",
    "code_agent = ChatCompletionAgent(\n",
    "    name=SOFTWARE_ENGINEER, \n",
    "    kernel=kernel,\n",
    "    instructions= \"\"\"\n",
    "    You are a professional Software Engineer. Your task is to write efficient, well-structured HTML, CSS, and JS code based on clear requirements.\n",
    "    All code should be in one code block, and you should not include any explanations or comments.\n",
    "    Output clean code only, enclosed within appropriate tags. Do not include explanations unless explicitly asked.   \n",
    "    \"\"\"\n",
    "    ) \n",
    "business_analyst_agent = ChatCompletionAgent(\n",
    "    name=BUSINESS_ANALYST, \n",
    "    kernel=kernel,\n",
    "    instructions=\"\"\"\"\n",
    "    You are a skilled Business Analyst. Based on the given instructions, your task is to view the requirements and create \n",
    "    a clear and concise summary of the requirements.\n",
    "    Your summary should be structured, highlighting key points and ensuring clarity for next agent.\n",
    "    Do not include any code or technical details, just a summary of the requirements.\n",
    "    \"\"\"\n",
    "    \n",
    "    )\n",
    "product_managet_agent = ChatCompletionAgent(\n",
    "    name=PRODUCT_MANAGER, \n",
    "    kernel=kernel,\n",
    "    instructions=\"\"\"\"\n",
    "     You are the Product Owner. Your job is to ensure that the Software Engineer's code meets all of the user's original requirements.\n",
    "\n",
    "Your responsibilities:\n",
    "- Cross-check the HTML implementation against the Business Analystâ€™s requirements.\n",
    "- Ensure all features are present and functioning as described. If yes please acknowledge with \"APPROVED\"\n",
    "- If any requirements are missing or not implemented correctly, provide specific feedback on what needs to be fixed.\n",
    "- Confirm that the Software Engineer has shared the code using this required format:\n",
    "   ```html\n",
    "   <!-- HTML content -->\n",
    "    \"\"\"\n",
    "    \n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "selection_function = KernelFunctionFromPrompt(\n",
    "    function_name=\"selection\", \n",
    "    prompt=f\"\"\"\n",
    "Examine the provided RESPONSE and choose the next participant.\n",
    "State only the name of the chosen participant without explanation.\n",
    "Never choose the participant named in the RESPONSE.\n",
    "\n",
    "Choose only from these participants:\n",
    "- {BUSINESS_ANALYST}\n",
    "- {SOFTWARE_ENGINEER}\n",
    "- {PRODUCT_MANAGER}\n",
    "\n",
    "Rules:\n",
    "- If RESPONSE is user input, it is {BUSINESS_ANALYST}'s turn.\n",
    "- If RESPONSE is by {BUSINESS_ANALYST}, it is {SOFTWARE_ENGINEER}'s turn.\n",
    "- If RESPONSE is by {SOFTWARE_ENGINEER}, it is {PRODUCT_MANAGER}'s turn.\n",
    "- If RESPONSE is by {PRODUCT_MANAGER} and it does not meet all the requirements, it is {SOFTWARE_ENGINEER}'s turn.\n",
    "- If RESPONSE is by {PRODUCT_MANAGER} and it meets all the requirements, Return RESPONSE with APPROVE Keyword.\n",
    "\n",
    "RESPONSE:\n",
    "{{{{$lastmessage}}}}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "termination_keyword = \"APPROVE\"\n",
    "\n",
    "termination_function = KernelFunctionFromPrompt(\n",
    "    function_name=\"termination\", \n",
    "    prompt=f\"\"\"\n",
    "Examine the RESPONSE and determine whether the content has been deemed satisfactory.\n",
    "If the content is satisfactory, respond with a single word without explanation: {termination_keyword}.\n",
    "If specific suggestions are being provided, it is not satisfactory.\n",
    "If no correction is suggested, it is satisfactory.\n",
    "\n",
    "RESPONSE:\n",
    "{{{{$lastmessage}}}}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "history_reducer = ChatHistoryTruncationReducer(target_count=1)\n",
    "\n",
    "chat = AgentGroupChat(\n",
    "    agents=[business_analyst_agent, code_agent, product_managet_agent],\n",
    "    selection_strategy=KernelFunctionSelectionStrategy(\n",
    "        initial_agent=business_analyst_agent,\n",
    "        function=selection_function,\n",
    "        kernel=kernel,\n",
    "        #result_parser=lambda result: str(result.value[0]).strip() if result.value[0] is not None else WRITER_NAME,\n",
    "        history_variable_name=\"lastmessage\",\n",
    "        history_reducer=history_reducer,\n",
    "    ),\n",
    "    termination_strategy=KernelFunctionTerminationStrategy(\n",
    "        agents=[product_managet_agent],\n",
    "        function=termination_function,\n",
    "        kernel=kernel,\n",
    "        result_parser=lambda result: termination_keyword in str(result.value[0]).lower(),\n",
    "        history_variable_name=\"lastmessage\",\n",
    "        maximum_iterations=10,\n",
    "        history_reducer=history_reducer,\n",
    "    ),\n",
    ")\n",
    "is_complete: bool = False\n",
    "while not is_complete:\n",
    "    print()\n",
    "    user_input = input(\"User > \").strip()\n",
    "    if not user_input:\n",
    "        continue\n",
    "    \n",
    "    if user_input.lower() == \"exit\":\n",
    "        is_complete = True\n",
    "        break\n",
    "    \n",
    "    if user_input.lower() == \"reset\":\n",
    "        await chat.reset()\n",
    "        print(\"[Conversation has been reset]\")\n",
    "        continue\n",
    "    \n",
    "    # Try to grab files from the script's current directory\n",
    "    if len(user_input) > 1:\n",
    "        await chat.add_chat_message(message=user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b231e7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "REVIEWER_NAME = \"Reviewer\"\n",
    "WRITER_NAME = \"Writer\"\n",
    "\n",
    "\n",
    "agent_reviewer = ChatCompletionAgent(\n",
    "        kernel=kernel,\n",
    "        name=REVIEWER_NAME,\n",
    "        instructions=\"\"\"\n",
    "Your responsibility is to review and identify how to improve user provided content.\n",
    "If the user has provided input or direction for content already provided, specify how to address this input.\n",
    "Never directly perform the correction or provide an example.\n",
    "Once the content has been updated in a subsequent response, review it again until it is satisfactory.\n",
    "\n",
    "RULES:\n",
    "- Only identify suggestions that are specific and actionable.\n",
    "- Verify previous suggestions have been addressed.\n",
    "- Never repeat previous suggestions.\n",
    "\"\"\",\n",
    ")\n",
    "\n",
    "agent_writer = ChatCompletionAgent(\n",
    "        kernel=kernel,\n",
    "        name=WRITER_NAME,\n",
    "        instructions=\"\"\"\n",
    "Your sole responsibility is to rewrite content according to review suggestions.\n",
    "- Always apply all review directions.\n",
    "- Always revise the content in its entirety without explanation.\n",
    "- Never address the user.\n",
    "\"\"\",\n",
    "    )\n",
    "\n",
    "\n",
    "selection_function = KernelFunctionFromPrompt(\n",
    "    function_name=\"selection\", \n",
    "    prompt=f\"\"\"\n",
    "Examine the provided RESPONSE and choose the next participant.\n",
    "State only the name of the chosen participant without explanation.\n",
    "Never choose the participant named in the RESPONSE.\n",
    "\n",
    "Choose only from these participants:\n",
    "- {REVIEWER_NAME}\n",
    "- {WRITER_NAME}\n",
    "\n",
    "Rules:\n",
    "- If RESPONSE is user input, it is {REVIEWER_NAME}'s turn.\n",
    "- If RESPONSE is by {REVIEWER_NAME}, it is {WRITER_NAME}'s turn.\n",
    "- If RESPONSE is by {WRITER_NAME}, it is {REVIEWER_NAME}'s turn.\n",
    "\n",
    "RESPONSE:\n",
    "{{{{$lastmessage}}}}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "termination_keyword = \"yes\"\n",
    "\n",
    "termination_function = KernelFunctionFromPrompt(\n",
    "    function_name=\"termination\", \n",
    "    prompt=f\"\"\"\n",
    "Examine the RESPONSE and determine whether the content has been deemed satisfactory.\n",
    "If the content is satisfactory, respond with a single word without explanation: {termination_keyword}.\n",
    "If specific suggestions are being provided, it is not satisfactory.\n",
    "If no correction is suggested, it is satisfactory.\n",
    "\n",
    "RESPONSE:\n",
    "{{{{$lastmessage}}}}\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "history_reducer = ChatHistoryTruncationReducer(target_count=1)\n",
    "\n",
    "chat = AgentGroupChat(\n",
    "    agents=[agent_reviewer, agent_writer],\n",
    "    selection_strategy=KernelFunctionSelectionStrategy(\n",
    "        initial_agent=agent_reviewer,\n",
    "        function=selection_function,\n",
    "        kernel=kernel,\n",
    "        result_parser=lambda result: str(result.value[0]).strip() if result.value[0] is not None else WRITER_NAME,\n",
    "        history_variable_name=\"lastmessage\",\n",
    "        history_reducer=history_reducer,\n",
    "    ),\n",
    "    termination_strategy=KernelFunctionTerminationStrategy(\n",
    "        agents=[agent_reviewer],\n",
    "        function=termination_function,\n",
    "        kernel=kernel,\n",
    "        result_parser=lambda result: termination_keyword in str(result.value[0]).lower(),\n",
    "        history_variable_name=\"lastmessage\",\n",
    "        maximum_iterations=10,\n",
    "        history_reducer=history_reducer,\n",
    "    ),\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e435556",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_complete: bool = False\n",
    "while not is_complete:\n",
    "    print()\n",
    "    user_input = input(\"User > \").strip()\n",
    "    if not user_input:\n",
    "        continue\n",
    "    \n",
    "    if user_input.lower() == \"exit\":\n",
    "        is_complete = True\n",
    "        break\n",
    "    \n",
    "    if user_input.lower() == \"reset\":\n",
    "        await chat.reset()\n",
    "        print(\"[Conversation has been reset]\")\n",
    "        continue\n",
    "    \n",
    "    # Try to grab files from the script's current directory\n",
    "    if user_input.startswith(\"@\") and len(user_input) > 1:\n",
    "        file_name = user_input[1:]\n",
    "        print(file_name)\n",
    "        #script_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "        file_path = \"./azsemantickernal/WomensSuffrage.txt\"\n",
    "        try:\n",
    "            #if not os.path.exists(file_path):\n",
    "            #    print(f\"Unable to access file: {file_path}\")\n",
    "            #    continue\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "                user_input = file.read()\n",
    "        except Exception:\n",
    "            print(f\"Unable to access file: {file_path}\")\n",
    "            continue\n",
    "\n",
    "# Add the current user_input to the chat\n",
    "await chat.add_chat_message(message=user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750e2e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    async for response in chat.invoke():\n",
    "        if response is None or not response.name:\n",
    "            continue\n",
    "        print()\n",
    "        print(f\"# {response.name.upper()}:\\n{response.content}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error during chat invocation: {e}\")\n",
    "\n",
    "# Reset the chat's complete flag for the new conversation round.\n",
    "chat.is_complete = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161a3391",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import asyncio\n",
    "import os\n",
    "\n",
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.agents import AgentGroupChat, ChatCompletionAgent\n",
    "from semantic_kernel.agents.strategies import (\n",
    "    KernelFunctionSelectionStrategy,\n",
    "    KernelFunctionTerminationStrategy,\n",
    ")\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "from semantic_kernel.contents import ChatHistoryTruncationReducer\n",
    "from semantic_kernel.functions import KernelFunctionFromPrompt\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Define agent names\n",
    "REVIEWER_NAME = \"Reviewer\"\n",
    "WRITER_NAME = \"Writer\"\n",
    "\n",
    "\n",
    "\n",
    "chat_completion_service = AzureChatCompletion(service_id=\"my-service-id\")\n",
    "\n",
    "kernel = Kernel()\n",
    "kernel.add_service(service=chat_completion_service)\n",
    "\n",
    "from semantic_kernel.connectors.ai.open_ai import OpenAIChatPromptExecutionSettings\n",
    "from semantic_kernel.contents.chat_history import ChatHistory\n",
    "\n",
    "execution_settings = OpenAIChatPromptExecutionSettings()\n",
    "\n",
    "chat_history = ChatHistory()\n",
    "chat_history.add_user_message(\"Hello, how are you?\")\n",
    "\n",
    "response = await chat_completion_service.get_chat_message_content(\n",
    "    chat_history=chat_history,\n",
    "    settings=execution_settings,\n",
    ")\n",
    "\n",
    "async for chunk in response:\n",
    "    print(chunk, end=\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
